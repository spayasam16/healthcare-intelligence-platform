# ğŸ¥ Healthcare Intelligence Platform â€“ Metadata-Driven Data Engineering Project

This project is a complete, end-to-end healthcare data engineering solution that simulates real-world pharma use cases like **HCP engagement tracking**, **shipment delay analysis**, and **product performance monitoring** â€” using a fully **metadata-driven** architecture built on **Databricks**, **PySpark**, and **SQL**.

---

## ğŸ” Business Use Case Simulated

This project mimics real-world operations of a pharma company by:

- Tracking HCP activity, specialty, and feedback  
- Monitoring delays in drug shipments  
- Analyzing product demand and performance  
- Enabling decision-makers to act quickly using BI dashboards  

**Dashboards Created**:
- ğŸ“Š **Executive Summary** â€“ Give leadership a birdâ€™s-eye view of product success, HCP engagement, and key risk indicators
- ğŸ§  **Operations & Risk Tracker (Ops/Logistics Team)** â€“ Help middle managers & ops teams track delivery performance, HCP activity, site issues.

All KPIs are built using 10 curated BI tables from the gold layer.

---

## ğŸš€ What This Project Demonstrates About Me

| Area | Demonstrated Skill |
|------|---------------------|
| ğŸ› ï¸ Data Engineering | Built and automated a full pipeline using PySpark + SQL in Databricks |
| ğŸ§  Metadata-Driven Pipelines | Configured jobs using dynamic config tables to reduce hardcoding |
| ğŸ—‚ï¸ Data Modeling | Designed both raw and analytical BI layer models |
| âš™ï¸ ETL / ELT | Implemented ingestion, cleansing, standardization, DQ, deduplication, and publishing |
| ğŸ§ª Data Quality | Applied rule-based validation using custom DQ rules from metadata |
| ğŸ“Š BI Dashboards | Created actionable dashboards using Databricks SQL |
| â˜ï¸ Cloud | Simulated S3 ingestion paths (Databricks Volumes), Unity Catalog for governance |
| âœ… Project Ownership | Took project from design â†’ implementation â†’ documentation and GitHub delivery |

---

## ğŸ§© Project Architecture

The pipeline is implemented across 3 modular notebooks:

### ğŸ§ª Notebooks

| Phase | Notebook | Description |
|-------|----------|-------------|
| ğŸ”„ Extract | [01_extract.py](notebooks/extract.py) | Ingests raw files (CSV/JSON) to raw/bronze Unity Catalog tables. |
| ğŸ”§ Transform | [02_transform.py](notebooks/transform.py) | Applies cleansing, standardization, DQ checks, and stages the data. |
| ğŸ“¥ Load & BI | [03_load.py](notebooks/load.py) | Loads to gold tables, applies deduplication, publishes BI tables. |


All layers are controlled by **metadata config tables** stored in Unity Catalog. The pipeline is **fully parameterized**, with dynamic behavior based on config and mapping rules.

ğŸ“Œ A detailed architecture flow diagram: `/architecture.png`

![Project Architecture](architecture.png)

---

## ğŸ§ª Technologies Used

- **Programming Languague - PySpark**
- **Scripting Languague - SparkSQL**
- **Databricks Community Edition**
    - **Unity Catalog Tables**
    - **Databricks SQL Dashboards**
- **Metadata-driven configs**
- **AWS S3 (simulated via Databricks Volumes)**

---

## Dataset Used
Here is the dataset used - https://github.com/spayasam16/healthcare-intelligence-platform/tree/0c785fbfeaaa5284b00e77fe5ae44274e7511336/data_sample

---

## Data Model

### Raw Data Model
![Raw Data Model](data_model/raw_data_model.png)

### BI Tables
![BI Data Model](data_model/BI_tables.png)

---

## Final Dashboards

![Executive Summary](bi_dashboards/Executive_Summary.PNG)

![Operations & Risk Tracker](bi_dashboards/Operations_Risk_Tracker.PNG)

---

## ğŸ“ Project Structure

```
healthcare-intelligence-platform/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_extract.py
â”‚   â”œâ”€â”€ 02_transform.py
â”‚   â””â”€â”€ 03_load.py
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ pipeline_config.csv
â”‚   â”œâ”€â”€ std_mapping.csv
â”‚   â”œâ”€â”€ dq_rules.csv
â”‚
â”œâ”€â”€ data_sample/
â”‚   â”œâ”€â”€ hcp_data.csv
â”‚   â”œâ”€â”€ product_ref.csv
â”‚   â””â”€â”€ ... (all 6 raw data files used)
â”‚
â”œâ”€â”€ bi_dashboards/
â”‚   â”œâ”€â”€ screenshots/
â”‚   â”‚   â”œâ”€â”€ dashboard_1_summary.png
â”‚   â”‚   â””â”€â”€ dashboard_2_engagement.png
â”‚   â””â”€â”€ dashboard_queries.sql
â”‚
â”œâ”€â”€ datamodels/
â”‚   â”œâ”€â”€ raw_data_model.png
â”‚   â”œâ”€â”€ bi_data_model.png
â”‚   â””â”€â”€ flow_diagram.png
â”‚
â””â”€â”€ README.md
```

---

## ğŸ’¼ Why This Project Matters for My Portfolio

- âœ… Designed with real-world enterprise readiness in mind  
- âœ… Shows skill with Databricks, PySpark, SQL, metadata-driven pipelines  
- âœ… Demonstrates ownership: from data modeling â†’ coding â†’ dashboards â†’ GitHub delivery  
- âœ… Mimics what real companies are hiring for in data engineer roles

---
